# üßµ Scraper Textil Argentina ‚Äî Gu√≠a Railway

## Archivos incluidos
```
scraper.py          ‚Üê el script principal
requirements.txt    ‚Üê dependencias Python
nixpacks.toml       ‚Üê config para Railway (instala Chromium)
```

---

## üìã PASO A PASO

### 1. Crear cuenta en Railway
- Entr√° a https://railway.app
- Registrate con tu cuenta de GitHub (es gratis)

---

### 2. Subir los archivos a GitHub
1. Entr√° a https://github.com y cre√° un repositorio nuevo
   - Nombre: `scraper-textil-argentina`
   - Privado ‚úÖ (recomendado)
2. Sub√≠ los 3 archivos: `scraper.py`, `requirements.txt`, `nixpacks.toml`
   - Hac√© click en "uploading an existing file"
   - Arrastr√° los 3 archivos juntos

---

### 3. Deployar en Railway
1. Entr√° a https://railway.app/new
2. Eleg√≠ **"Deploy from GitHub repo"**
3. Conect√° tu cuenta de GitHub y seleccion√° `scraper-textil-argentina`
4. Railway va a detectar autom√°ticamente el `nixpacks.toml`
5. Hac√© click en **Deploy** ‚úÖ

---

### 4. Ver los logs en tiempo real
- En Railway, hac√© click en tu proyecto ‚Üí pesta√±a **"Deployments"**
- Vas a ver los logs con los leads encontrados en tiempo real:
  ```
  üîç Buscando: 'f√°brica textil Argentina'
     ‚Üí 18 resultados encontrados
     ‚úÖ [1] Textil San Mart√≠n | +54 11 4xxx | www.textilsm.com.ar
     ‚úÖ [2] Confecciones Norte | +54 351 4xxx | ...
  ```

---

### 5. Descargar el CSV con los leads
Railway no tiene almacenamiento persistente por defecto, as√≠ que ten√©s 2 opciones:

#### Opci√≥n A ‚Äî Google Drive (recomendado)
Agreg√° esto al final del `scraper.py` para subir el CSV autom√°ticamente:
```python
# Instalar: pip install google-auth google-auth-oauthlib google-api-python-client
# Ver gu√≠a: https://developers.google.com/drive/api/quickstart/python
```
(Avisame y te armo esto tambi√©n)

#### Opci√≥n B ‚Äî Ver en logs
El script imprime cada lead en los logs, pod√©s copiarlos desde Railway.

#### Opci√≥n C ‚Äî Railway Volume (m√°s simple)
1. En Railway ‚Üí tu proyecto ‚Üí **"+ New"** ‚Üí **"Volume"**
2. Mont√° el volumen en `/app`
3. El CSV se va a guardar ah√≠ y pod√©s descargarlo

---

## ‚öôÔ∏è Ajustes opcionales

Abr√≠ `scraper.py` y modific√° estas variables al principio:

| Variable | Default | Descripci√≥n |
|---|---|---|
| `MAX_RESULTADOS_POR_BUSQUEDA` | 20 | Sub√≠ a 50 para m√°s leads |
| `BUSQUEDAS` | 10 b√∫squedas | Agreg√° o quit√° rubros |
| `DELAY_MIN / DELAY_MAX` | 2.5 / 5.0 seg | Aument√° si hay captchas |

---

## ‚ùì Problemas frecuentes

**Error: "No such file chromium"**
‚Üí Verific√° que `nixpacks.toml` est√° en la ra√≠z del repo

**El scraper se detiene pronto**
‚Üí Google puede mostrar captcha. Aument√° los delays o esper√° unas horas

**No veo resultados**
‚Üí Google cambi√≥ su HTML. Avisame y actualizo los selectores

---

## üí∞ Costo en Railway
- Plan gratuito: **$5 de cr√©dito/mes** (suficiente para correr el scraper varias veces)
- El scraper tarda ~20-40 minutos en completar todas las b√∫squedas
